# ğŸ–¼ï¸â¡ï¸ğŸŒ AWS Reddit Image Translation Pipeline

> **AI-Powered Image Text Extraction and Translation System**
> Automatically detect, extract, and translate text from your photos or Reddit images using AWS AI services including Rekognition, Comprehend, and Translate.

## ğŸ“š Documentation Hub

| Document                                               | Purpose                   | Key Topics                                                                         |
| ------------------------------------------------------ | ------------------------- | ---------------------------------------------------------------------------------- |
| **ğŸ“„ [Reddit Pipeline Documentation](src/README.md)**  | Complete technical guide  | Reddit API integration, AWS service architecture, module APIs, deployment patterns |
| **ğŸ—ï¸ [Infrastructure Guide](terraform/README.md)**    | Infrastructure automation | Terraform deployment, cost optimization, security best practices                   |
| **ğŸŒ [Frontend Deployment Guide](frontend/README.md)** | Web interface setup       | Cognito authentication, S3 integration, deployment options                         |
| **ğŸ”„ [Storage Adapter Guide](STORAGE_ADAPTER.md)**     | Storage backend switching | AWS S3 â†” Google Cloud Storage, free tier optimization                            |

## ğŸ—ï¸ System Architecture Overview

**Core Components:**

* ğŸŒ **Reddit Integration**: Automated content discovery and image extraction
* ğŸ“¸ **AWS Rekognition**: OCR text detection and extraction from images
* ğŸ§  **AWS Comprehend**: Intelligent language detection and confidence scoring
* ğŸŒ **AWS Translate**: Multi-language text translation with 75+ language support
* ğŸ“Š **DynamoDB**: Stateful processing tracking and Reddit post management
* ğŸ—„ï¸ **S3 Storage**: Secure image storage with encryption and lifecycle management
* ğŸ”§ **Lambda Functions**: Serverless execution environment for scalable processing

## âš™ï¸ Prerequisites and Requirements

### ğŸ–¥ï¸ System Requirements

* ğŸ **Python 3.8+** (actively tested with Python 3.13.2)
* â˜ï¸ **AWS Account** with appropriate permissions for AI/ML services
* ğŸ”‘ **Reddit API credentials** for content access

### ğŸ” AWS Credentials Setup

Before running any AWS operations, configure your AWS credentials securely. Create the following credential files with your AWS access keys and region:

**`~/.aws/credentials`:**

```ini
[default]
aws_access_key_id = YOUR_ACCESS_KEY_ID
aws_secret_access_key = YOUR_SECRET_ACCESS_KEY
```

**`~/.aws/config`:**

```ini
[default]
region=us-east-1
```

**Alternative Methods:**

* âš™ï¸ AWS CLI: `aws configure`
* ğŸŒ± Environment variables: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`
* ğŸ›¡ï¸ IAM roles

## ğŸš€ Quick Start Guide

### ğŸ› ï¸ Virtual Environment Setup

```bash
python -m venv .venv
source .venv/Scripts/activate  # Windows
python -m pip install --upgrade pip
pip install .[dev]
```

### ğŸŒ Local Development Setup (Recommended)

Launch frontend with Live Server and use the local FastAPI backend:

```bash
# 1. Create Cognito resources for authentication
python setup_cognito.py

# 2. Add the output to .env.local file

# 3. Start the backend
fastapi dev backend/app.py

# 4. Open frontend/index.html with Live Server
```

### ğŸƒ Running the CLI

The main entry point is `main.py`, which provides a command-line interface to detect and translate text from images in an S3 bucket.

#### ğŸ“‹ Usage

```bash
python main.py [--bucket BUCKET] [--target-lang TGT_LANG]
```

**Parameters:**

* ğŸ—ƒï¸ `--bucket`: S3 bucket name (default: value from `config.py`)
* ğŸŒ `--target-lang`: Target language code (default: value from `config.py`)

**Example:**

```bash
python main.py --bucket mybucket --target-lang en
```

If no arguments are provided, the defaults from `config.py` will be used. The source language is automatically detected using AWS Comprehend.

### ğŸŒ± Environment Variables

Before running the application, create a `.env.local` file in the project root with your Reddit API credentials:

```env
REDDIT_CLIENT_ID=your_client_id
REDDIT_CLIENT_SECRET=your_client_secret
REDDIT_USER_AGENT=python:translate-images-bot:1.0 (by u/yourusername)

# Optional: Override default AWS settings
AWS_REGION=us-east-1
DYNAMODB_TABLE_NAME=reddit_ingest_state
```

**Key Configuration Settings (`config.py`):**

* ğŸ—‚ï¸ **S3\_IMAGE\_BUCKET**: `"ajbarea-aws-translate"` - S3 bucket for image storage
* ğŸŒ **SOURCE\_LANGUAGE\_CODE**: `"es"` - Default source language (Spanish)
* ğŸŒ **TARGET\_LANGUAGE\_CODE**: `"en"` - Default target language (English)
* ğŸ“ **AWS\_REGION**: `"us-east-1"` - AWS region for all services

## ğŸ”„ Storage Backend Management

### ğŸ“¦ Quick Storage Backend Switching

The project includes a **Storage Adapter** for seamless switching between AWS S3 and Google Cloud Storage - perfect for development when hitting free tier limits.

```bash
# Check current storage backend
python configure_storage.py --status

# Switch to Google Cloud Storage
python configure_storage.py --backend gcs --bucket-name gcloud-image-bucket

# Switch back to AWS S3
python configure_storage.py --backend aws
```

### ğŸ”§ Google Cloud Storage Quick Setup

```bash
# Install dependencies
python configure_storage.py --install-gcs

# Authenticate
gcloud auth application-default login

# Switch backend
python configure_storage.py --backend gcs --bucket-name gcloud-image-bucket
```

### ğŸ“Š Free Tier Benefits

| Storage Provider | Free Tier Limits |
|------------------|------------------|
| **AWS S3** | 5 GB storage, 20K GET/2K PUT operations |
| **Google Cloud Storage** | 5 GB storage, 5K Class A/50K Class B operations |
| **Combined** | **~10 GB total development capacity!** |

> **ğŸ“– For detailed configuration, troubleshooting, and advanced features, see the [Storage Adapter Guide](STORAGE_ADAPTER.md)**

## ğŸ› ï¸ Infrastructure Management

### ğŸš§ Infrastructure Deployment

1. **Initialize and deploy infrastructure:**

   ```bash
   cd terraform
   terraform init
   terraform plan
   terraform apply
   ```

2. **ğŸ§¹ Clean up resources (Important - Avoid AWS costs):**

   ```bash
   cd terraform
   terraform destroy
   ```

## ğŸ§ª Testing & Development

### âœ… Running Tests

```bash
pytest --cov=src

# Check for branches missing coverage
python -m pytest --cov=src --cov-report=term-missing --cov-branch
```

### ğŸ§° Development Tools and Code Quality

This project uses a suite of modern Python development tools to ensure high code quality and consistency. Code formatting, linting, and type-checking are automated using `pre-commit` hooks.

The primary tools include:

* ğŸ§ª **`pytest`**: For running the comprehensive test suite.
* ğŸ¨ **`black`**: For opinionated, consistent code formatting.
* â— **`isort`**: For automatically sorting imports.
* ğŸš¨ **`flake8`**: For enforcing style and complexity rules.
* ğŸ” **`mypy`**: For static type checking.

#### ğŸ”„ Running Quality Checks

To run all code quality checks and formatters across the entire project, use the provided script:

```bash
./lint.sh
```

## ğŸ›ï¸ Project Architecture Details

### ğŸ’» Technology Stack

**ğŸ–¥ï¸ Backend:**

* **Python 3.13.2**: Core application language with modern features
* **AWS SDK (boto3)**: Cloud service integration
* **Reddit API (PRAW)**: Automated content discovery
* **BeautifulSoup4**: HTML parsing for media extraction

**ğŸŒ Infrastructure:**

* **Terraform**: Infrastructure as Code for reproducible deployments
* **AWS Services**: S3, DynamoDB, Rekognition, Translate, Comprehend, Lambda
* **GitHub Actions**: CI/CD pipeline with automated testing and quality checks

**ğŸ¨ Frontend:**

* **Vanilla JavaScript**: Lightweight, fast, no frameworks required
* **AWS SDK for JavaScript**: Direct AWS service integration
* **AWS Cognito**: Secure user authentication and authorization

## ğŸ“š Documentation and Resources

### â˜ï¸ AWS Service Documentation

* [AWS Rekognition Text Detection](https://docs.aws.amazon.com/rekognition/latest/dg/text-detecting-text-procedure.html)
* [AWS S3 Developer Guide](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/list_objects_v2.html)
* [AWS Translate API Reference](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/translate/client/translate_text.html)
* [AWS Lambda Python Runtime](https://docs.aws.amazon.com/lambda/latest/dg/python-programming-model.html)

### ğŸ“’ Development Resources

* [Python PRAW Documentation](https://praw.readthedocs.io/en/stable/)
* [Terraform AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)
* [pytest Documentation](https://docs.pytest.org/en/stable/)
* [AWS SDK for Python (Boto3)](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)

### ğŸ¤ Community Resources

* [Build Your Own Translator App Tutorial](https://community.aws/content/2drbcpmaBORz25L3e74AM6EIcFj/build-your-own-translator-app-in-less-30-min)
